# Google-Colab_Notebooks
A Collection of Google Colab Notebooks for scripts & projects



| Notebook | Info
| --- | --- |
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/ComfyUI/Qwen_Image_Edit_Plus/ComfyUI_Qwen_Image_Edit_2509.ipynb)  | ComfyUI - 1 to 3 Images to 1 Image with Qwen Image Edit 2509
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/ComfyUI/Wan_2_2_Animate/ComfyUI_Wan22_Animate.ipynb)  | ComfyUI - Img+Vid2Vid with Wan2.2 Animate (Tested on the L4)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/ComfyUI/Wan22_VACE_Fun/ComfyUI_Wan22_VACE_Fun_A14B_preVACE.ipynb)  | ComfyUI - Img+Vid2Vid with VACE Fun (Compute units Required)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/ComfyUI/ComfyUI_Flux1Dev_USO/ComfyUI_Flux1Dev_USO.ipynb)  | ComfyUI - Style and Subject-Driven Image Generation with Flux.1Dev-USO
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/ComfyUI/Qwen_Image_with_DiffSynth_Control_LoRA/ComfyUI_Qwen_Image_with_Diffsynth_Control_Union_LoRA.ipynb)  | ComfyUI - Img2Img with Qwen + DiffSynth-Control-LoRA
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/ComfyUI/Qwen_Image_with_DiffSynth_Controlnet/ComfyUI_Qwen_Image_with_DiffSynth_ControlNet_Model_Patches.ipynb)  | ComfyUI - Img2Img with Qwen + DiffSynth-ControlNet (Depth, Canny, Inpaint) (Compute units Required)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/ComfyUI/Qwen_Image_with_InstantX_Controlnet_and_DMPt_Nodes/ComfyUI_Qwen_Image_Instant_X_Control_with_DMPt_Nodes.ipynb)  | ComfyUI - Img2Img with Qwen + InstantX-ControlNet-Union 
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/video2Gif_(Basic).ipynb)  | Video to Gif (basic)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/LatentSync.ipynb)  | Lip Sync with LatentSync
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Animate_X.ipynb)  | Animation with Animate-X
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/ZonosTTS.ipynb)  | TTS with ZonosTTS
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_T2V_1_3B_DiffSynth.ipynb)  | T2V & T2I with Wan2.1_T2V_1.3B (Compute units Required)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_T2V_14B.ipynb)  | T2V & T2I with Wan2_1_T2V_14B (Compute units Required)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_I2V_14B.ipynb)  | Image to Video with Wan2_1_I2V_14B-480P (Compute units Required)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/FrameInterpolationRIFE.ipynb)  | Frame Interpolation with RIFE
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/LTX_Video_Img_to_Vid.ipynb)  | Basic Image to Video with LTX-Video
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/LTX_Video_Tx_to_Vid.ipynb)  | Text to Video with LTX-Video
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/LTX_Video_with_Start_&_End_frames.ipynb)  | Two Images to Video with LTX-Video
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_1_3B_T2V_Free.ipynb)  | T2V & T2I with Wan2.1_T2V_1.3B
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_14B_T2V_GGUF_Free.ipynb)  | T2V & T2I with Wan2.1_T2V_14B GGUF Models
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_14B_I2V_GGUF_Free.ipynb)  | Image to Video with Wan2.1_I2V_14B-480p GGUF Models
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_14B_I2V_GGUF_&_LoRA.ipynb)  | I2V with Wan2.1_I2V_14B-480p GGUF Models & LoRA
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Fast_Wan2_1_14B_I2V_480p_GGUF_&_LoRA.ipynb)  | Faster I2V with Wan2.1_I2V_14B-480p GGUF Models, LoRA & Teacache
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Hidream_fp8.ipynb)  | Hidream_fp8 for Text to Image Generation (Compute units Required)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Hidream_T2V_GGUF_Q5.ipynb)  | Hidream_GGUF_Q5 for Text to Image Generation
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/FramePack.ipynb)  | FramePack_fp8 for Image to Video Generation (Compute units Required)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Flux_Upscaler.ipynb)  | Upscale Images & Videos with Flux Upscaler
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/ICEdit.ipynb)  | Use Prompts to Edit Images with In-Context Edit
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/LTXV_0_9_7_13B_Distilled_Image_to_Video.ipynb)  | LTXV-0.9.7-13B_Distilled_GGUF_Q6 for Image to Video Generation
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Basic_Wan2_1_VACE_&_CausVid_LoRA_4_Text_to_Video(WIP).ipynb)  | Wan 2.1 VACE 14B & CausVid LoRA for faster Text to Video Generation
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Basic_Wan2_1_VACE_&_CausVid_LoRA_4_Image_to_Video.ipynb)  | Wan 2.1 VACE 14B & CausVid LoRA for faster Image to Video Generation
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_VACE_&_CausVid_LoRA_4_Video_to_Video.ipynb)  | Wan 2.1 VACE 14B & CausVid LoRA for Video to Video Generation
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Wan2_1_VACE_Img2Img_PoseTransfer.ipynb)  | Wan 2.1 VACE 14B & CausVid LoRA for Image to Image Pose Transfer (Experimental)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/flux/Flux1_Kontext_Dev.ipynb)  | Use Prompts to Edit Images with Flux.1 Kontext Dev
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/wan_2_1/Faster_wan2_1_Causvid_Lightx2v_FusionX.ipynb)  | Faster I2V with Wan2.1 using Causvid, Lightx2v & Fusionx LoRAs
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/wan2_2/wan22_Lightx2v.ipynb)  | I2V with Wan2.2 using Lightx2v LoRA
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/wan2_2/wan22_T2V_Lightx2v.ipynb)  | T2V with Wan2.2 using Lightx2v LoRA
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/wan2_2/wan22_FirstLastFrame2Video.ipynb)  | First-Last Frame to Video with Wan2.2
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Sonic_Image_Audio_to_Video.ipynb)  | Audio-driven Portrait Animation with Sonic
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/wan_2_1/wan21_based_InfiniteTalk_&_MultiTalk.ipynb)  | Audio-driven Animation with InfiniteTalk & MultiTalk (Compute units Required)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Qwen_Image/Qwen_Image_Gen_Edit.ipynb)  | Qwen-Image for Generating & Editing Images 
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/Qwen_Image/Qwen_Image_Edit_Plus.ipynb)  | Qwen-Image-Edit 2509 for 1-3 Images to 1 Image
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isi-dev/Google-Colab_Notebooks/blob/main/flux/Flux1_Kontext_Dev_with_Mask_Editor_for_Inpainting.ipynb)  | Flux1 Kontext Dev with Mask Editor for Inpainting




You can find more notebooks [here](https://isinse.gumroad.com/) 

Some of the comfyUI workflows are modifications of Kijai's workflows which you can find [here](https://github.com/kijai/ComfyUI-WanVideoWrapper/tree/main/example_workflows)

## Support
If you find these notebooks helpful, you can support me here:  [![Buy Me a Coffee](https://img.shields.io/badge/Support-Buy%20Me%20a%20Coffee-orange?style=flat-square&logo=buy-me-a-coffee)](https://buymeacoffee.com/isiomo)

## Contributing
I currently don't have the time to review pull requests. If you find any bugs or run into issues, please report them in the Issues section. Thanks!


