{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Chroma1-HD for Text to Image Generation**\n",
        "- Project page: https://huggingface.co/lodestones/Chroma1-HD\n",
        "- Notebook source: https://github.com/Isi-dev/Google-Colab_Notebooks\n",
        "- Premium notebooks I highly recommend: https://isinse.gumroad.com/\n",
        "- Even $1 helps support my work: https://buymeacoffee.com/isiomo\n"
      ],
      "metadata": {
        "id": "8gNEkuc4oyv8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F-3uUiopZ2hy",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @markdown # ðŸ’¥1. Setup Environment\n",
        "# !pip install --quiet torch torchvision --index-url https://download.pytorch.org/whl/cu124\n",
        "# !pip install --upgrade --quiet torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install torch==2.8.0 torchvision==0.23.0\n",
        "%cd /content\n",
        "\n",
        "from IPython.display import clear_output\n",
        "!git clone --branch ComfyUI_v0.3.65 https://github.com/Isi-dev/ComfyUI\n",
        "clear_output()\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "# !git clone https://github.com/Isi-dev/ComfyUI_Img2PaintingAssistant\n",
        "!git clone https://github.com/Isi-dev/ComfyUI_GGUF.git\n",
        "clear_output()\n",
        "# !git clone https://github.com/Isi-dev/ComfyUI_KJNodes.git\n",
        "# clear_output()\n",
        "%cd /content/ComfyUI/custom_nodes/ComfyUI_GGUF\n",
        "!pip install -r requirements.txt\n",
        "clear_output()\n",
        "# %cd /content/ComfyUI/custom_nodes/ComfyUI_KJNodes\n",
        "# !pip install -r requirements.txt\n",
        "# clear_output()\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_pip_packages():\n",
        "    packages = [\n",
        "        'torchsde',\n",
        "        'av',\n",
        "        'diffusers',\n",
        "        # 'transformers',\n",
        "        'xformers==0.0.32.post1',\n",
        "        'accelerate',\n",
        "        # 'omegaconf',\n",
        "        # 'tqdm',\n",
        "        # 'librosa',\n",
        "        'einops',\n",
        "        'spandrel'\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            # Run pip install silently (using -q)\n",
        "            subprocess.run(\n",
        "                [sys.executable, '-m', 'pip', 'install', '-q', package],\n",
        "                check=True,\n",
        "                capture_output=True\n",
        "            )\n",
        "            print(f\"âœ“ {package} installed\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"âœ— Error installing {package}: {e.stderr.decode().strip() or 'Unknown error'}\")\n",
        "\n",
        "def install_apt_packages():\n",
        "    packages = ['aria2']\n",
        "\n",
        "    try:\n",
        "        # Run apt install silently (using -qq)\n",
        "        subprocess.run(\n",
        "            ['apt-get', '-y', 'install', '-qq'] + packages,\n",
        "            check=True,\n",
        "            capture_output=True\n",
        "        )\n",
        "        print(\"âœ“ apt packages installed\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"âœ— Error installing apt packages: {e.stderr.decode().strip() or 'Unknown error'}\")\n",
        "\n",
        "\n",
        "print(\"Installing pip packages...\")\n",
        "install_pip_packages()\n",
        "clear_output()  # Clear the pip installation output\n",
        "\n",
        "print(\"Installing apt packages...\")\n",
        "install_apt_packages()\n",
        "clear_output()  # Clear the apt installation output\n",
        "\n",
        "print(\"Installation completed with status:\")\n",
        "print(\"- All pip packages installed successfully\" if 'âœ—' not in install_pip_packages.__code__.co_consts else \"- Some pip packages had issues\")\n",
        "print(\"- apt packages installed successfully\" if 'âœ—' not in install_apt_packages.__code__.co_consts else \"- apt packages had issues\")\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import random\n",
        "import imageio\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML, Image as IPImage\n",
        "sys.path.insert(0, '/content/ComfyUI')\n",
        "\n",
        "from nodes import (\n",
        "    UNETLoader,\n",
        "    DualCLIPLoader,\n",
        "    CLIPLoader,\n",
        "    CLIPTextEncode,\n",
        "    VAEEncode,\n",
        "    VAEEncodeForInpaint,\n",
        "    VAEDecode,\n",
        "    VAELoader,\n",
        "    KSampler,\n",
        "    ConditioningZeroOut,\n",
        "    InpaintModelConditioning,\n",
        "    ImageScaleBy,\n",
        "    ImageScale,\n",
        "    LoraLoaderModelOnly,\n",
        "    LoadImage,\n",
        "    SaveImage\n",
        ")\n",
        "\n",
        "# from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF\n",
        "from comfy_extras.nodes_model_advanced import ModelSamplingSD3\n",
        "\n",
        "from comfy_extras.nodes_sd3 import EmptySD3LatentImage\n",
        "\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "download_loRA = False\n",
        "lora = None\n",
        "\n",
        "def download_with_aria2c(link, folder=\"/content/ComfyUI/models/loras\"):\n",
        "    import os\n",
        "\n",
        "    filename = link.split(\"/\")[-1]\n",
        "    command = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {link} -d {folder} -o {filename}\"\n",
        "\n",
        "    print(\"Executing download command:\")\n",
        "    print(command)\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    get_ipython().system(command)\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "\n",
        "def download_civitai_model(civitai_link, civitai_token, folder=\"/content/ComfyUI/models/loras\"):\n",
        "    import os\n",
        "    import time\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        model_id = civitai_link.split(\"/models/\")[1].split(\"?\")[0]\n",
        "    except IndexError:\n",
        "        raise ValueError(\"Invalid Civitai URL format. Please use a link like: https://civitai.com/api/download/models/1523247?...\")\n",
        "\n",
        "    civitai_url = f\"https://civitai.com/api/download/models/{model_id}?type=Model&format=SafeTensor\"\n",
        "    if civitai_token:\n",
        "        civitai_url += f\"&token={civitai_token}\"\n",
        "\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"model_{timestamp}.safetensors\"\n",
        "\n",
        "    full_path = os.path.join(folder, filename)\n",
        "\n",
        "    download_command = f\"wget --max-redirect=10 --show-progress \\\"{civitai_url}\\\" -O \\\"{full_path}\\\"\"\n",
        "    print(\"Downloading from Civitai...\")\n",
        "\n",
        "    os.system(download_command)\n",
        "\n",
        "    local_path = os.path.join(folder, filename)\n",
        "    if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
        "        print(f\"LoRA downloaded successfully: {local_path}\")\n",
        "    else:\n",
        "        print(f\"âŒ LoRA download failed or file is empty: {local_path}\")\n",
        "\n",
        "    return filename\n",
        "\n",
        "\n",
        "def download_lora(link, folder=\"/content/ComfyUI/models/loras\", civitai_token=None):\n",
        "    \"\"\"\n",
        "    Download a model file, automatically detecting if it's a Civitai link or huggingface download.\n",
        "\n",
        "    Args:\n",
        "        link: The download URL (either huggingface or Civitai)\n",
        "        folder: Destination folder for the download\n",
        "        civitai_token: Optional token for Civitai downloads (required if link is from Civitai)\n",
        "\n",
        "    Returns:\n",
        "        The filename of the downloaded model\n",
        "    \"\"\"\n",
        "    if \"civitai.com\" in link.lower():\n",
        "        if not civitai_token:\n",
        "            raise ValueError(\"Civitai token is required for Civitai downloads\")\n",
        "        return download_civitai_model(link, civitai_token, folder)\n",
        "    else:\n",
        "        return download_with_aria2c(link, folder)\n",
        "\n",
        "flux_lora_download_url = \"https://huggingface.co/Isi99999/Upscalers/resolve/main/Flux/Facezoom_Kontext_LoRA.safetensors\"\n",
        "token_if_civitai_url = \"Put your civitai token here\"\n",
        "if download_loRA:\n",
        "    lora = download_lora(flux_lora_download_url, civitai_token=token_if_civitai_url)\n",
        "# Validate loRA file extension\n",
        "valid_extensions = {'.safetensors', '.ckpt', '.pt', '.pth', '.sft'}\n",
        "if lora:\n",
        "    if not any(lora.lower().endswith(ext) for ext in valid_extensions):\n",
        "        print(f\"âŒ Invalid LoRA format: {lora}\")\n",
        "        lora = None\n",
        "    else:\n",
        "        clear_output()\n",
        "        print(\"loRA downloaded succesfully!\")\n",
        "\n",
        "def model_download(url: str, dest_dir: str, filename: str = None, silent: bool = True) -> bool:\n",
        "    \"\"\"\n",
        "    Colab-optimized download with aria2c\n",
        "\n",
        "    Args:\n",
        "        url: Download URL\n",
        "        dest_dir: Target directory (will be created if needed)\n",
        "        filename: Optional output filename (defaults to URL filename)\n",
        "        silent: If True, suppresses all output (except errors)\n",
        "\n",
        "    Returns:\n",
        "        bool: True if successful, False if failed\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create destination directory\n",
        "        Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Set filename if not specified\n",
        "        if filename is None:\n",
        "            filename = url.split('/')[-1].split('?')[0]  # Remove URL parameters\n",
        "\n",
        "        # Build command\n",
        "        cmd = [\n",
        "            'aria2c',\n",
        "            '--console-log-level=error',\n",
        "            '-c', '-x', '16', '-s', '16', '-k', '1M',\n",
        "            '-d', dest_dir,\n",
        "            '-o', filename,\n",
        "            url\n",
        "        ]\n",
        "\n",
        "        # Add silent flags if requested\n",
        "        if silent:\n",
        "            cmd.extend(['--summary-interval=0', '--quiet'])\n",
        "            print(f\"Downloading {filename}...\", end=' ', flush=True)\n",
        "\n",
        "        # Run download\n",
        "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "\n",
        "        if silent:\n",
        "            print(\"Done!\")\n",
        "        else:\n",
        "            print(f\"Downloaded {filename} to {dest_dir}\")\n",
        "        return filename\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        error = e.stderr.strip() or \"Unknown error\"\n",
        "        print(f\"\\nError downloading {filename}: {error}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "chroma_HD_Model = \"https://huggingface.co/silveroxides/Chroma1-HD-fp8-scaled/resolve/main/Chroma1-HD-fp8_scaled_rev2.safetensors\" # @param {\"type\":\"string\"}\n",
        "t5xxl_model =\"https://huggingface.co/silveroxides/t5xxl_flan_enc/resolve/main/t5xxl_flan_new_alt_fp8_e4m3fn_scaled.safetensors\" # @param {\"type\":\"string\"}\n",
        "chroma_vae = \"https://huggingface.co/lodestones/Chroma1-HD/resolve/main/vae/diffusion_pytorch_model.safetensors\" # @param {\"type\":\"string\"}\n",
        "lora = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "\n",
        "chroma_model = model_download(chroma_HD_Model, \"/content/ComfyUI/models/unet\")\n",
        "flux_vae = model_download(chroma_vae, \"/content/ComfyUI/models/vae\")\n",
        "t5xxl = model_download(t5xxl_model , \"/content/ComfyUI/models/clip\")\n",
        "turbo_lora = model_download(lora, \"/content/ComfyUI/models/loras\")\n",
        "\n",
        "\n",
        "# clip_loader = DualCLIPLoader()\n",
        "clip_loader = CLIPLoader()\n",
        "# unet_loader =  UnetLoaderGGUF()\n",
        "unet_loader =  UNETLoader()\n",
        "vae_loader =   VAELoader()\n",
        "vae_encode = VAEEncode()\n",
        "vae_decode = VAEDecode()\n",
        "ksampler = KSampler()\n",
        "load_lora = LoraLoaderModelOnly()\n",
        "load_turbo_lora = LoraLoaderModelOnly()\n",
        "model_sampling = ModelSamplingSD3()\n",
        "save_image = SaveImage()\n",
        "positive_prompt_encode = CLIPTextEncode()\n",
        "negative_prompt_encode = CLIPTextEncode()\n",
        "\n",
        "empty_latent_image = EmptySD3LatentImage()\n",
        "\n",
        "\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "    for obj in list(globals().values()):\n",
        "        if torch.is_tensor(obj) or (hasattr(obj, \"data\") and torch.is_tensor(obj.data)):\n",
        "            del obj\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "def save_as_image(image, filename_prefix, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save single frame as PNG image.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.png\"\n",
        "\n",
        "    frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
        "\n",
        "    Image.fromarray(frame).save(output_path)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "\n",
        "def generate_image(\n",
        "    positive_prompt: str = \"\",\n",
        "    negative_prompt: str = \"\",\n",
        "    guidance: float = 2.5,\n",
        "    width: int = 832,\n",
        "    height: int = 480,\n",
        "    seed: int = 0,\n",
        "    steps: int = 20,\n",
        "    cfg: float = 1.0,\n",
        "    shift: float = 1.0,\n",
        "    sampler_name: str = \"euler\",\n",
        "    scheduler: str = \"simple\",\n",
        "    denoise: float = 1.0,\n",
        "    use_turbo_lora: bool = False,\n",
        "    LoRA_Strength: float = 1.0,\n",
        "    overwrite: bool = False\n",
        "\n",
        "):\n",
        "\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        print(\"Loading Text_Encoder...\")\n",
        "        clip = clip_loader.load_clip(t5xxl, \"chroma\")[0]\n",
        "\n",
        "\n",
        "        positive = positive_prompt_encode.encode(clip, positive_prompt)[0]\n",
        "\n",
        "        negative = negative_prompt_encode.encode(clip, negative_prompt)[0]\n",
        "\n",
        "\n",
        "        del clip\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        try:\n",
        "            print(\"Loading Unet Model...\")\n",
        "            model = unet_loader.load_unet(chroma_model, \"default\")[0]\n",
        "            # model = model_sampling.patch(model, shift)[0]\n",
        "\n",
        "            if use_turbo_lora and turbo_lora is not None:\n",
        "                print(\"Loading turbo Lora...\")\n",
        "                model = load_turbo_lora.load_lora_model_only(model, turbo_lora, LoRA_Strength)[0]\n",
        "\n",
        "\n",
        "            latent = empty_latent_image.generate(width, height, 1)[0]\n",
        "\n",
        "            clear_output()\n",
        "\n",
        "            print(\"Generating Image...\")\n",
        "            image_out_latent = ksampler.sample(\n",
        "                model=model,\n",
        "                seed=seed,\n",
        "                steps=steps,\n",
        "                cfg=cfg,\n",
        "                sampler_name=sampler_name,\n",
        "                scheduler=scheduler,\n",
        "                positive=positive,\n",
        "                negative=negative,\n",
        "                latent_image=latent,\n",
        "                denoise=1\n",
        "            )[0]\n",
        "\n",
        "            del model\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            print(\"Loading VAE...\")\n",
        "            vae = vae_loader.load_vae(flux_vae)[0]\n",
        "\n",
        "            print(\"Decoding latents...\")\n",
        "            decoded = vae_decode.decode(vae, image_out_latent)[0]\n",
        "\n",
        "            del vae\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            base_name = \"ComfyUI\"\n",
        "            if not overwrite:\n",
        "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                base_name += f\"_{timestamp}\"\n",
        "\n",
        "            outputImagePath = save_as_image(decoded[0], base_name)\n",
        "            display(IPImage(filename=outputImagePath))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during Image Generation/saving: {str(e)}\")\n",
        "            raise\n",
        "        finally:\n",
        "            clear_memory()\n",
        "\n",
        "clear_output()\n",
        "\n",
        "\n",
        "print(\"âœ… Environment Setup Complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown # ðŸ’¥4. Generate Image\n",
        "\n",
        "positive_prompt=\"A high-fashion close-up portrait of a blonde woman in clear sunglasses. The image uses a bold teal and red color split for dramatic lighting. The background is a simple teal-green. The photo is sharp and well-composed, and is designed for viewing with anaglyph 3D glasses for optimal effect. It looks professionally done.\" # @param {\"type\":\"string\"}\n",
        "negative_prompt=\"low quality, ugly, unfinished, out of focus, deformed, disfigure, blurry, smudged, restricted palette, flat colors\" # @param {\"type\":\"string\"}\n",
        "guidance=2.5\n",
        "\n",
        "width = 768 # @param {\"type\":\"number\"}\n",
        "height = 768 # @param {\"type\":\"number\"}\n",
        "\n",
        "overwrite_previous_output=False # @param {type:\"boolean\"}\n",
        "# @markdown ---\n",
        "# @markdown ### Sampler Settings\n",
        "seed=0 # @param {\"type\":\"integer\"}\n",
        "steps = 26 # @param {\"type\":\"slider\",\"min\":0,\"max\":100,\"step\":1}\n",
        "cfg = 3.8 # @param {\"type\":\"slider\",\"min\":0,\"max\":20,\"step\":0.1}\n",
        "shift = 1.0\n",
        "sampler_name=\"euler\" # @param [\"uni_pc\", \"uni_pc_bh2\", \"ddim\",\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\",\"dpm_2\", \"dpm_2_ancestral\",\"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\",\"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\",\"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\",\"gradient_estimation\", \"er_sde\", \"seeds_2\", \"seeds_3\"]\n",
        "scheduler=\"simple\" # @param [\"simple\",\"normal\",\"karras\",\"exponential\",\"sgm_uniform\",\"ddim_uniform\",\"beta\",\"linear_quadratic\",\"kl_optimal\"]\n",
        "denoise=1\n",
        "# @markdown ---\n",
        "# @markdown ### LoRA Settings\n",
        "# use_turbo_lora=False # @param {type:\"boolean\"}\n",
        "use_lora=False # @param {type:\"boolean\"}\n",
        "LoRA_Strength=1 # @param {\"type\":\"slider\",\"min\":-1,\"max\":1,\"step\":0.01}\n",
        "\n",
        "\n",
        "import random\n",
        "seed = seed if seed != 0 else random.randint(0, 2**32 - 1)\n",
        "print(f\"Using seed: {seed}\")\n",
        "\n",
        "\n",
        "\n",
        "generate_image(\n",
        "    positive_prompt = positive_prompt,\n",
        "    negative_prompt = negative_prompt,\n",
        "    guidance = guidance,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    seed = seed,\n",
        "    steps = steps,\n",
        "    cfg = cfg,\n",
        "    shift=shift,\n",
        "    sampler_name = sampler_name,\n",
        "    scheduler = scheduler,\n",
        "    denoise = denoise,\n",
        "    use_turbo_lora = use_lora,\n",
        "    LoRA_Strength = LoRA_Strength,\n",
        "    overwrite = overwrite_previous_output\n",
        ")\n",
        "\n",
        "clear_memory()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "D9NFwJVBaD78"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}